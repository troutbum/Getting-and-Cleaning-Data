makeCacheMatrix <- function(x = matrix()) {
invCached <- matrix(data = NA, nrow = 1,                # set cached inverse matrix to "empty"
ncol = 1, byrow = FALSE,
dimnames = NULL)
set <- function(y) {                                    # method to store data matrix
x <<- y
invCached <<- matrix(NA, 1, 1, FALSE, NULL)     # reset cached inverse to "empty"
}
get <- function() x                                     # method to retrieve data matrix
setInverse <- function(inverse) invCached <<- inverse   # method to store mean
getInverse <- function() invCached                      # method to retrieve mean
list(set = set, get = get, setInverse = setInverse, getInverse = getInverse)
}
cacheSolve <- function(x, ...) {
## Return a matrix that is the inverse of 'x'
inverse <- x$getInverse()               # retrieve cached inverse
if(!is.na(inverse[1,1])) {              # if not empty, return cached inverse
message("getting cached
inverse matrix")
return(inverse)                 # use invisible(inverse) to suppress print()
}
data <- x$get()                         # otherwise get cached data
inverse <- solve(data, ...)             # calculate the inverse
x$setInverse(inverse)                   # save the inverse into cache
inverse
}
size <- 10                                      # create data (square matrix)
mydata <- matrix(rnorm(size*size), size, size)
M1 <- makeCacheMatrix()                         # create caching data structure
M1
environment(M1)
M1$set(mydata)                                  # place data into structure
M1$getInverse()                                 # get inverse (empty at this point)
imat <- cacheSolve(M1)                          # calculate the inverse
imat_cached <- cacheSolve(M1)                   # caculate the inverse again (retrieved cached value)
identical(imat, imat_cached)                    # verify inverse and cached inversed are the same
test <- mydata %*% imat                         # verify matrix %*% inverse = identity matrix
View(test)
## R Programming - April 2014
## Programming Assignment 2 - Caching the Inverse of a Matrix
##
# In this example we introduce the <<- operator which can be used to assign a
# value to an object in an environment that is different from the current
# environment.
# Below are two functions that are used to create a special object
# that stores a matrix and cache's its inverse.
#
# The first function, makeVector creates a special "vector", which is really a
# list containing a function to:
# - set the matrix
# - get matrix
# - set matrix inverse
# - get matrix inverse
makeCacheMatrix <- function(x = matrix()) {
invCached <- matrix(data = NA, nrow = 1,                # set cached inverse matrix to "empty"
ncol = 1, byrow = FALSE,
dimnames = NULL)
set <- function(y) {                                    # method to store data matrix
x <<- y
invCached <<- matrix(NA, 1, 1, FALSE, NULL)     # reset cached inverse to "empty"
}
get <- function() x                                     # method to retrieve data matrix
setInverse <- function(inverse) invCached <<- inverse   # method to store mean
getInverse <- function() invCached                      # method to retrieve mean
list(set = set, get = get, setInverse = setInverse, getInverse = getInverse)
}
# The second function calculates the inverse of the object. It checks to see if the inverse
# has already been calculated. Ff not, it calculates the inverse and stores it
# in the object.  Returns a matrix that is the inverse of 'x'
cacheSolve <- function(x, ...) {
inverse <- x$getInverse()               # retrieve cached inverse
if(!is.na(inverse[1,1])) {              # if not empty, return cached inverse
message("getting cached inverse matrix")
return(inverse)                 # use invisible(inverse) to suppress print()
}
data <- x$get()                         # otherwise get cached data
inverse <- solve(data, ...)             # calculate the inverse
x$setInverse(inverse)                   # save the inverse into cache
inverse
}
# Now use these functions to generate an inverse matrix and cache it. Verify that
# the calculated and cached inverses are identical Verify that the matrix
# multiplied by its inverse is equal to the identity matrix
size <- 10                                       # create test data (square matrix)
mydata <- matrix(rnorm(size*size), size, size)
mat <- makeCacheMatrix()                         # create caching data structure
mat
mat$set(mydata)                                  # place data into structure
mat$getInverse()                                 # get inverse (empty at this point)
imat <- cacheSolve(mat)                          # calculate the inverse
imat_cached <- cacheSolve(mat)                   # caculate the inverse again (retrieved cached value)
identical(imat, imat_cached)                     # verify inverse and cached inversed are the same
test <- mydata %*% imat                          # verify matrix %*% inverse = identity matrix
View(test)
Food_Display_Table <- read.table("~/Downloads/MyFoodapediaData/Food_Display_Table.xml", quote="\"")
View(Food_Display_Table)
Inpatient_Prospective_Payment_System__IPPS__Provider_Summary_for_the_Top_100_Diagnosis.Related_Groups__DRG_ <- read.csv("~/Downloads/Inpatient_Prospective_Payment_System__IPPS__Provider_Summary_for_the_Top_100_Diagnosis-Related_Groups__DRG_.csv")
View(Inpatient_Prospective_Payment_System__IPPS__Provider_Summary_for_the_Top_100_Diagnosis.Related_Groups__DRG_)
R.Version()
install.packages("xlsx")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
download.file(fileUrl, destfile = "./data/NGAP.xlsx", method ="curl")
library(xlsx)
rowIndex <- 18:23
colIndex <- 7:15
dat <- read.xlsx("./data/NGAP.xlsx,sheetIndex=1,colIndex=colIndex,rowIndex=rowIndex")
?read.xlsx
?xlsx
dat <- read.xlsx("./data/NGAP.xlsx, sheetIndex=0 ,colIndex=colIndex, rowIndex=rowIndex")
dat <- read.xlsx("./data/NGAP.xlsx, sheetIndex=1 ,colIndex=colIndex, rowIndex=rowIndex")
install.packages("RMySQL")
install.packages(c("MASS", "swirl"))
install.packages("RMySQL")
setwd("~/CourseraHW/Getting-and-Cleaning-Data/Week3")
# Getting and Cleaning Data
# May 2014
# Quiz 3
# Question 3
# Load the Gross Domestic Product data for the 190 ranked countries in this data set:
#
#         https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv
#
# Load the educational data from this data set:
#
#         https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv
#
# Match the data based on the country shortcode. How many of the IDs match? Sort
# the data frame in descending order by GDP rank. What is the 13th country in
# the resulting data frame?
#
# Original data sources:
#       http://data.worldbank.org/data-catalog/GDP-ranking-table
#       http://data.worldbank.org/data-catalog/ed-stats
#
# 190, St. Kitts and Nevis
# 189, St. Kitts and Nevis
# 189, Spain
# 234, St. Kitts and Nevis
# 234, Spain
# 190, Spain
# create a data subdirectory if it does not exist
if (!file.exists("data")) {
dir.create("data")
}
filePath <- "./data/"
# download dataset
fileName <- "getdata-data-GDP.csv"
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
xFile <- paste0(filePath, fileName)
if (!file.exists(xFile)) {
download.file(fileUrl, destfile = xFile, method ="curl")
dateDownloaded <- date()
}
# read in dataset
GDP <- read.csv(xFile, skip=4, nrows=190)     # BIG LESSON limit row reads with wonky data
# weird unstable behavior downstream
# download dataset
fileName <- "getdata-data-EDSTATS_Country.csv"
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
xFile <- paste0(filePath, fileName)
if (!file.exists(xFile)) {
download.file(fileUrl, destfile = xFile, method ="curl")
dateDownloaded <- date()
}
# read in dataset
ED <- read.csv(xFile)
EDx <- subset(ED,, c(CountryCode, Long.Name, Income.Group))     # remove extraneous columns
# cleanup GDP df
names(GDP)[1] <- "CountryCode"
names(GDP)[2] <- "Rank"
GDPx <- subset(GDP,, c(CountryCode, Rank))      # remove extraneous columns
library(plyr)
joint = join(GDPx, EDx, by="CountryCode")                                          # 190 matches, Spain is 13th
print(head(joint[,1:2], n=20))
# Question 4
# What is the average GDP ranking for the "High income: OECD" and "High income: nonOECD" group?
# 32.96667, 91.91304
# 23.966667, 30.91304
# 23, 45
# 23, 30
# 30, 37
# 133.72973, 32.96667
# use aggregate() to create dataset that contains the average
table(joint$Income.Group)  # check numbers of each group
OECD <- joint[ which(joint$Income.Group=='High income: OECD'),]
row.names(OECD) <- NULL                                         # removes row.names system added column
nonOECD <- joint[ which(joint$Income.Group=='High income: nonOECD'),]
row.names(nonOECD) <- NULL
avgRankOECD <- mean(OECD[,2])
avgRankOECD
avgRanknonOECD <- mean(nonOECD[,2])
avgRanknonOECD
# Question 5
# Cut the GDP ranking into 5 separate quantile groups. Make a table versus
# Income.Group. How many countries are Lower middle income but among the 38
# nations with highest GDP?
# 1
# 13
# 5
# 3
quantile(joint$Rank,probs=c(0.1,0.3,0.5,0.7,0.9))
table(joint$Income.Group)
# create logical vectors
income <- joint$Income.Group == "Lower middle income"
summary(income)
ranking <- joint$Rank <= 38
summary(ranking)
both = income & ranking
summary(both)
which(both)
joint[both,]            # produces a list of countries meeting both conditions
# create a data subdirectory if it does not exist
if (!file.exists("data")) {
dir.create("data")
}
filePath <- "./data/"
# download dataset
fileName <- "getdata-data-GDP.csv"
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
xFile <- paste0(filePath, fileName)
if (!file.exists(xFile)) {
download.file(fileUrl, destfile = xFile, method ="curl")
dateDownloaded <- date()
}
# read in dataset
GDP <- read.csv(xFile, skip=4)       # BIG LESSON limit row reads with wonky data
#GDP <- read.csv(xFile, skip=4, nrows=190)       # weird unstable behavior downstream
# download dataset
fileName <- "getdata-data-EDSTATS_Country.csv"
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
xFile <- paste0(filePath, fileName)
if (!file.exists(xFile)) {
download.file(fileUrl, destfile = xFile, method ="curl")
dateDownloaded <- date()
}
# read in dataset
ED <- read.csv(xFile)
# create a data subdirectory if it does not exist
if (!file.exists("data")) {
dir.create("data")
}
filePath <- "./data/"
# download dataset
fileName <- "getdata-data-GDP.csv"
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
xFile <- paste0(filePath, fileName)
if (!file.exists(xFile)) {
download.file(fileUrl, destfile = xFile, method ="curl")
dateDownloaded <- date()
}
# read in dataset
GDP <- read.csv(xFile, skip=4)       # BIG LESSON limit row reads with wonky data
#GDP <- read.csv(xFile, skip=4, nrows=190)       # weird unstable behavior downstream
# download dataset
fileName <- "getdata-data-EDSTATS_Country.csv"
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
xFile <- paste0(filePath, fileName)
if (!file.exists(xFile)) {
download.file(fileUrl, destfile = xFile, method ="curl")
dateDownloaded <- date()
}
# read in dataset
ED <- read.csv(xFile)
EDcodes <-as.character(ED[,1])
GDPcodes <-as.character(GDP[,1])
GDPcodes
summary(GDPcodes)
str(GDPcodes)
GDPcodes %in% c("")
!(GDPcodes %in% c(""))
summary(!(GDPcodes %in% c("")))
summary(EDcodes)
EDcodes
e <-as.character(ED[,1])
g <-as.character(GDP[,1])
gg <- g[g != ""]
summary(!(g %in% c("")))
e %in% gg
?intersect
intersect(gg,e)
summary(intersect(gg,e))
summary(intersect(g,e))
View(GDP)
View(ED)
matches <- intersect(g,e)
GDP2 <- GDP[GDP != ""]
View(GDP)
GDP2 <- GDP[GDP[,2] != ""]
GDP2 <- GDP[GDP[1:190,]]
GDP2 <- GDP[1:190,]
View(GDP2)
matches2 <- intersect(GDP2[,2],e)
GDP2[,2]
View(GDP2)
matches2 <- intersect(GDP2[,1],e)
# create a data subdirectory if it does not exist
if (!file.exists("data")) {
dir.create("data")
}
filePath <- "./data/"
# download dataset
fileName <- "getdata-data-GDP.csv"
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
xFile <- paste0(filePath, fileName)
if (!file.exists(xFile)) {
download.file(fileUrl, destfile = xFile, method ="curl")
dateDownloaded <- date()
}
# read in dataset
GDP <- read.csv(xFile, skip=4)       # BIG LESSON limit row reads with wonky data
#GDP <- read.csv(xFile, skip=4, nrows=190)       # weird unstable behavior downstream
# download dataset
fileName <- "getdata-data-EDSTATS_Country.csv"
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
xFile <- paste0(filePath, fileName)
if (!file.exists(xFile)) {
download.file(fileUrl, destfile = xFile, method ="curl")
dateDownloaded <- date()
}
# read in dataset
ED <- read.csv(xFile)
e <-as.character(ED[,1])
g <-as.character(GDP[,1])
# how many blank entries
summary(!(e %in% c("")))
summary(!(g %in% c("")))
g <- g[g != ""]
summary(!(g %in% c("")))
matches <- intersect(e,g)
matches
summary(matches)
str(matches)
# Getting and Cleaning Data
# May 2014
# Quiz 3
# REDO QUIZ - NEED TO FIGURE OUT CRAZY R BEHAVIOR WITH WONKY DATA
# Question 3
# Load the Gross Domestic Product data for the 190 ranked countries in this data set:
#
#         https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv
#
# Load the educational data from this data set:
#
#         https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv
#
# Match the data based on the country shortcode. How many of the IDs match? Sort
# the data frame in descending order by GDP rank. What is the 13th country in
# the resulting data frame?
#
# Original data sources:
#       http://data.worldbank.org/data-catalog/GDP-ranking-table
#       http://data.worldbank.org/data-catalog/ed-stats
#
# 190, St. Kitts and Nevis
# 189, St. Kitts and Nevis
# 189, Spain
# 234, St. Kitts and Nevis
# 234, Spain
# 190, Spain
# create a data subdirectory if it does not exist
if (!file.exists("data")) {
dir.create("data")
}
filePath <- "./data/"
# download dataset
fileName <- "getdata-data-GDP.csv"
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
xFile <- paste0(filePath, fileName)
if (!file.exists(xFile)) {
download.file(fileUrl, destfile = xFile, method ="curl")
dateDownloaded <- date()
}
# read in dataset
GDP <- read.csv(xFile, skip=4)       # BIG LESSON limit row reads with wonky data
#GDP <- read.csv(xFile, skip=4, nrows=190)       # weird unstable behavior downstream
# download dataset
fileName <- "getdata-data-EDSTATS_Country.csv"
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
xFile <- paste0(filePath, fileName)
if (!file.exists(xFile)) {
download.file(fileUrl, destfile = xFile, method ="curl")
dateDownloaded <- date()
}
# read in dataset
ED <- read.csv(xFile)
# subset DFs to just CountryCode vectors for comparison
e <-as.character(ED[,1])
g <-as.character(GDP[,1])
# how many empty elements
summary(!(e %in% c("")))
summary(!(g %in% c("")))
# strip out empty elements
g <- g[g != ""]
summary(!(g %in% c("")))
# compare intersection of these vectors
matches <- intersect(e,g)
str(matches)
# subset GDP to observations with Rank (190 observations)
gg <- GDP[1:190,]
matches2 <- intersect(e,gg[,1])
str(matches2)
View(gg)
matches2[13]
