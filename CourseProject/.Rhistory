makeCacheMatrix <- function(x = matrix()) {
invCached <- matrix(data = NA, nrow = 1,                # set cached inverse matrix to "empty"
ncol = 1, byrow = FALSE,
dimnames = NULL)
set <- function(y) {                                    # method to store data matrix
x <<- y
invCached <<- matrix(NA, 1, 1, FALSE, NULL)     # reset cached inverse to "empty"
}
get <- function() x                                     # method to retrieve data matrix
setInverse <- function(inverse) invCached <<- inverse   # method to store mean
getInverse <- function() invCached                      # method to retrieve mean
list(set = set, get = get, setInverse = setInverse, getInverse = getInverse)
}
cacheSolve <- function(x, ...) {
## Return a matrix that is the inverse of 'x'
inverse <- x$getInverse()               # retrieve cached inverse
if(!is.na(inverse[1,1])) {              # if not empty, return cached inverse
message("getting cached
inverse matrix")
return(inverse)                 # use invisible(inverse) to suppress print()
}
data <- x$get()                         # otherwise get cached data
inverse <- solve(data, ...)             # calculate the inverse
x$setInverse(inverse)                   # save the inverse into cache
inverse
}
size <- 10                                      # create data (square matrix)
mydata <- matrix(rnorm(size*size), size, size)
M1 <- makeCacheMatrix()                         # create caching data structure
M1
environment(M1)
M1$set(mydata)                                  # place data into structure
M1$getInverse()                                 # get inverse (empty at this point)
imat <- cacheSolve(M1)                          # calculate the inverse
imat_cached <- cacheSolve(M1)                   # caculate the inverse again (retrieved cached value)
identical(imat, imat_cached)                    # verify inverse and cached inversed are the same
test <- mydata %*% imat                         # verify matrix %*% inverse = identity matrix
View(test)
## R Programming - April 2014
## Programming Assignment 2 - Caching the Inverse of a Matrix
##
# In this example we introduce the <<- operator which can be used to assign a
# value to an object in an environment that is different from the current
# environment.
# Below are two functions that are used to create a special object
# that stores a matrix and cache's its inverse.
#
# The first function, makeVector creates a special "vector", which is really a
# list containing a function to:
# - set the matrix
# - get matrix
# - set matrix inverse
# - get matrix inverse
makeCacheMatrix <- function(x = matrix()) {
invCached <- matrix(data = NA, nrow = 1,                # set cached inverse matrix to "empty"
ncol = 1, byrow = FALSE,
dimnames = NULL)
set <- function(y) {                                    # method to store data matrix
x <<- y
invCached <<- matrix(NA, 1, 1, FALSE, NULL)     # reset cached inverse to "empty"
}
get <- function() x                                     # method to retrieve data matrix
setInverse <- function(inverse) invCached <<- inverse   # method to store mean
getInverse <- function() invCached                      # method to retrieve mean
list(set = set, get = get, setInverse = setInverse, getInverse = getInverse)
}
# The second function calculates the inverse of the object. It checks to see if the inverse
# has already been calculated. Ff not, it calculates the inverse and stores it
# in the object.  Returns a matrix that is the inverse of 'x'
cacheSolve <- function(x, ...) {
inverse <- x$getInverse()               # retrieve cached inverse
if(!is.na(inverse[1,1])) {              # if not empty, return cached inverse
message("getting cached inverse matrix")
return(inverse)                 # use invisible(inverse) to suppress print()
}
data <- x$get()                         # otherwise get cached data
inverse <- solve(data, ...)             # calculate the inverse
x$setInverse(inverse)                   # save the inverse into cache
inverse
}
# Now use these functions to generate an inverse matrix and cache it. Verify that
# the calculated and cached inverses are identical Verify that the matrix
# multiplied by its inverse is equal to the identity matrix
size <- 10                                       # create test data (square matrix)
mydata <- matrix(rnorm(size*size), size, size)
mat <- makeCacheMatrix()                         # create caching data structure
mat
mat$set(mydata)                                  # place data into structure
mat$getInverse()                                 # get inverse (empty at this point)
imat <- cacheSolve(mat)                          # calculate the inverse
imat_cached <- cacheSolve(mat)                   # caculate the inverse again (retrieved cached value)
identical(imat, imat_cached)                     # verify inverse and cached inversed are the same
test <- mydata %*% imat                          # verify matrix %*% inverse = identity matrix
View(test)
Food_Display_Table <- read.table("~/Downloads/MyFoodapediaData/Food_Display_Table.xml", quote="\"")
View(Food_Display_Table)
Inpatient_Prospective_Payment_System__IPPS__Provider_Summary_for_the_Top_100_Diagnosis.Related_Groups__DRG_ <- read.csv("~/Downloads/Inpatient_Prospective_Payment_System__IPPS__Provider_Summary_for_the_Top_100_Diagnosis-Related_Groups__DRG_.csv")
View(Inpatient_Prospective_Payment_System__IPPS__Provider_Summary_for_the_Top_100_Diagnosis.Related_Groups__DRG_)
R.Version()
install.packages("xlsx")
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
download.file(fileUrl, destfile = "./data/NGAP.xlsx", method ="curl")
library(xlsx)
rowIndex <- 18:23
colIndex <- 7:15
dat <- read.xlsx("./data/NGAP.xlsx,sheetIndex=1,colIndex=colIndex,rowIndex=rowIndex")
?read.xlsx
?xlsx
dat <- read.xlsx("./data/NGAP.xlsx, sheetIndex=0 ,colIndex=colIndex, rowIndex=rowIndex")
dat <- read.xlsx("./data/NGAP.xlsx, sheetIndex=1 ,colIndex=colIndex, rowIndex=rowIndex")
install.packages("RMySQL")
install.packages(c("MASS", "swirl"))
install.packages("RMySQL")
setwd("~/CourseraHW/Getting-and-Cleaning-Data/CourseProject")
# Getting and Cleaning Data
# May 2014
# Course Project
# The purpose of this project is to demonstrate your ability to collect, work
# with, and clean a data set. The goal is to prepare tidy data that can be used
# for later analysis. You will be graded by your peers on a series of yes/no
# questions related to the project. You will be required to submit: 1) a tidy
# data set as described below, 2) a link to a Github repository with your script
# for performing the analysis, and 3) a code book that describes the variables,
# the data, and any transformations or work that you performed to clean up the
# data called CodeBook.md. You should also include a README.md in the repo with
# your scripts. This repo explains how all of the scripts work and how they are
# connected.
#
# One of the most exciting areas in all of data science right now is wearable
# computing - see for example this article . Companies like Fitbit, Nike, and
# Jawbone Up are racing to develop the most advanced algorithms to attract new
# users. The data linked to from the course website represent data collected
# from the accelerometers from the Samsung Galaxy S smartphone. A full
# description is available at the site where the data was obtained:
#
# http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones
#
# Here are the data for the project:
#
# https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip
#
# You should create one R script called run_analysis.R that does the following:
#
# - Merges the training and the test sets to create one data set.
# - Extracts only the measurements on the mean and standard deviation for each
#   measurement.
# - Uses descriptive activity names to name the activities in the data set.
# - Appropriately labels the data set with descriptive activity names.
# - Creates a second, independent tidy data set with the average of each variable
#   for each activity and each subject.
# download file if it isn't already there
if (!file.exists("getdata-projectfiles-UCI HAR Dataset.zip")) {
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fprojectfiles%2FUCI%20HAR%20Dataset.zip"
fileName <- "getdata-projectfiles-UCI HAR Dataset.zip"
download.file(fileUrl, destfile=fileName, method ="curl")
unzip(fileName)
dateDownloaded <- date()
}
# read in variable names
filePath <- "./UCI HAR Dataset/"                                # path set in zipped file
features.txt <- read.table(paste(filePath,
"features.txt",sep=""))
variable.names <- as.character(features.txt[,2])                # column labels for dataset
# create logical vector to extract a subset of columns
contains.mean <- grepl("mean()",variable.names,fixed=TRUE)      # returns logical vector containing
contains.std <- grepl("std()",variable.names,fixed=TRUE)        #  "mean()", "std()", meanFreq()
contains.meanfreq <- grepl("meanFreq()",variable.names,fixed=TRUE)
selected.cols <- contains.mean | contains.std | contains.meanfreq
# initial clean up of variable names
names <- gsub("()","",variable.names,fixed=TRUE)                # finds and replaces bad characters
names <- gsub("-","",names,fixed=TRUE)                          # from dataset
names <- gsub("mean",".Mean",names,fixed=TRUE)
names <- gsub("std",".Std",names,fixed=TRUE)
# read in training measurements (7352 rows)
measurements.train <- read.table(paste(filePath,"train/X_train.txt",sep=""),
col.names=as.character(names))
# read in test measurements (2947 rows)
measurements.test <- read.table(paste(filePath,"test/X_test.txt",sep=""),
col.names=as.character(names))
# extract columns of interest using logical vector
data.train <- measurements.train[,selected.cols == TRUE]
datasource <- rep(c("train"), nrow(data.train))                 # add column to mark source of data
data.train <- cbind(datasource, data.train )                    # from training data file
data.test <- measurements.test[,selected.cols == TRUE]
datasource <- rep(c("test"), nrow(data.test))
data.test <- cbind(datasource, data.test )                      # from test data file
data = rbind(data.train, data.test)                             # combine training and test rows
# subject ID for each observation (30 possible volunteers)
subject.id.train <- read.table(paste(filePath,"train/subject_train.txt",sep=""),
col.names=c("subject.id"))
subject.id.test <- read.table(paste(filePath,"test/subject_test.txt",sep=""),
col.names=c("subject.id"))
subject.id = rbind(subject.id.train, subject.id.test)
# activity ID for each observation (6 types)
activity.id.train <- read.table(paste(filePath,"train/y_train.txt",sep=""),
col.names=c("id"))
activity.id.test <- read.table(paste(filePath,"test/y_test.txt",sep=""),
col.names=c("id"))
activity.id = rbind(activity.id.train, activity.id.test)
# description labels for the 6 activities
activity.labels <- read.table(paste(filePath,"activity_labels.txt",sep=""),
col.names=c("id","activity"))
# join tables to get activity description instead of activity number
library(plyr)
activity = join(activity.id, activity.labels)
# combine dataset with Subject ID and Activity columns
x <- cbind(activity$activity, activity$id, data)
names(x)[1] <- "activity"                                       # rename added columns
names(x)[2] <- "activity.id"
xx <- cbind(subject.id, x)
# sort dataset by (subject.id, activity)
results <- xx[order(xx$subject.id, xx$activity),]
row.names(results) <- NULL                                      # remove row.names system added column
# use aggregate() to create "tidy dataset" that contains the average
# of each variable by subject and activity
tidydata <-aggregate(results, by=list(results$datasource,
results$subject.id,
results$activity), FUN=mean)
tidydata <- subset(tidydata,,-c(subject.id, activity,
datasource))                    # remove extraneous columns
names(tidydata)[1] <- "datasource"
names(tidydata)[2] <- "subject.id"
names(tidydata)[3] <- "activity"
# cleanup names per assignment specification
tidynames <- tolower(names(tidydata))                           # make names lowercase
tidynames <- gsub("acc","accelerometer",tidynames,fixed=TRUE)
tidynames <- gsub("gyro","gyroscope",tidynames,fixed=TRUE)
tidynames <- gsub("mag","magnitude",tidynames,fixed=TRUE)
tidynames <- gsub("std","standarddeviation",tidynames,fixed=TRUE)
tidynames <- gsub("freq","frequency",tidynames,fixed=TRUE)
tidynames <- gsub("tbody","timebody",tidynames,fixed=TRUE)
tidynames <- gsub("tgravity","timegravity",tidynames,fixed=TRUE)
tidynames <- gsub("fbody","fastfouriertransformbody",tidynames,fixed=TRUE)
tidynames <- gsub(".","",tidynames,fixed=TRUE)
# apply cleaned names to tidydata
names(tidydata) <- tidynames
# write output
write.csv(tidydata, "tidydata.txt", row.names=FALSE)             # caution: row.names added by default
install.packages("Hmisc")
library(Hmisc)
describe(tidydata)
?describe
summary(tidydata)
summary(activity)
str(tidydata)
str(tidydata$activity)
